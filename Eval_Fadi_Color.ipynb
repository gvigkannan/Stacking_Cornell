{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook to evaluate and store the results from ggcnn for a sample imageset\n",
    "## Last Trial Run: 7th April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import sys \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data \n",
    "import imageio\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggcnn_dir = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/ggcnn_repo/\"\n",
    "fadi_dir = \"/media/gvk/GVK_Elements/github_repo/Ensemble/Experts/Generative/pretrained_weights\"\n",
    "sys.path.append(ggcnn_dir)\n",
    "sys.path.append(fadi_dir)\n",
    "from models.common import post_process_output\n",
    "from utils.dataset_processing import evaluation, grasp \n",
    "from utils.data import get_dataset\n",
    "from utils.dataset_processing.image import DepthImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search Path:  /media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/*/*/pcd*cpos.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_path = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/*/\"\n",
    "dataset = get_dataset(\"cornell\")\n",
    "sys.path.insert(0, dataset_path)\n",
    "test_data = dataset(dataset_path, include_depth = False, include_rgb = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search Path:  /media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/data01/*/pcd*cpos.txt\n"
     ]
    }
   ],
   "source": [
    "## Considering one folder!\n",
    "# folder1_path = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/data01/\"\n",
    "# dataset = get_dataset(\"cornell\")\n",
    "# sys.path.insert(0, folder1_path)\n",
    "# test_data = dataset(folder1_path, include_depth = False, include_rgb = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "len(test_data.depth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Loading:\n",
    "fadi_depth_dir = \"/media/gvk/GVK_Elements/github_repo/Stacking_Cornell/Experts/Generative/pretrained_weights/color/epoch_37_iou_0.80\"\n",
    "depth_net = torch.load(fadi_depth_dir)\n",
    "net = depth_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comp = test_data\n",
    "test_data = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cell Time:  0.17312932014465332\n"
     ]
    }
   ],
   "source": [
    "##  Trial for each test image\n",
    "start_cell = time.time()\n",
    "results = {'correct': 0, 'failed': 0}\n",
    "iou_quality = {}\n",
    "with torch.no_grad():\n",
    "\n",
    "    ## For each test image\n",
    "    ## Just testing for one single image\n",
    "    x, y, didx, rot, zoom =  next(iter(test_data))\n",
    "    idx = 0\n",
    "    xc = x.to(device)\n",
    "    yc = [yi.to(device) for yi in y]\n",
    "    lossd = net.compute_loss(xc, yc)    ## Ensure that your outputs are from a dataloader!\n",
    "\n",
    "    q_img, ang_img, width_img = post_process_output( lossd['pred']['pos'], lossd['pred']['cos'], lossd['pred']['sin'], lossd['pred']['width'])\n",
    "    s = evaluation.calculate_iou_match(q_img, ang_img, test_data.dataset.get_gtbb(didx, rot, zoom), no_grasps = 1, grasp_width = width_img)\n",
    "\n",
    "    if s:\n",
    "        results['correct'] += 1\n",
    "    else:\n",
    "        results['failed'] += 1\n",
    "\n",
    "    iou_dict = {}\n",
    "    ## Now to compare and create a dictionary that stores the quality given image name\n",
    "    x_comp, _, _, _, _ = test_comp[idx]\n",
    "    #print(torch.allclose(torch.tensor(x_comp), x))\n",
    "    if torch.allclose(torch.tensor(x_comp), x):\n",
    "        img_id = test_comp.depth_files[0].split(\"/\")[-1]\n",
    "\n",
    "        ## We cannot use an image!\n",
    "        #quality_dict[str(img_id)] = q_img\n",
    "        image_id = str(img_id).split('.')[0][:-1]\n",
    "        iou_quality[image_id] = [int(s), np.max(q_img).astype('float32')]\n",
    "    else:\n",
    "        print(\"Dataloader and Comparison X didn't match\")\n",
    "\n",
    "print(\"Cell Time: \", time.time() - start_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cell Time:  182.27391147613525\n"
     ]
    }
   ],
   "source": [
    "results = {'correct': 0, 'failed': 0}\n",
    "start_cell = time.time()\n",
    "iou_quality = {}\n",
    "with torch.no_grad():\n",
    "\n",
    "    ## For each test image\n",
    "    ## Just testing for one single image\n",
    "    #x, y, didx, rot, zoom =  next(iter(test_data))\n",
    "    for idx, (x, y, didx, rot, zoom) in enumerate(test_data):\n",
    "        xc = x.to(device)\n",
    "        yc = [yi.to(device) for yi in y]\n",
    "        lossd = net.compute_loss(xc, yc)\n",
    "\n",
    "        q_img, ang_img, width_img = post_process_output( lossd['pred']['pos'], lossd['pred']['cos'], lossd['pred']['sin'], lossd['pred']['width'])\n",
    "        s = evaluation.calculate_iou_match(q_img, ang_img, test_data.dataset.get_gtbb(didx, rot, zoom), no_grasps = 1, grasp_width = width_img)\n",
    "\n",
    "        if s:\n",
    "            results['correct'] += 1\n",
    "        else:\n",
    "            results['failed'] += 1\n",
    "\n",
    "        ## Need to store: q_img and img_id\n",
    "        ## Now to compare and create a dictionary that stores the quality given image name\n",
    "        x_comp, _, _, _, _ = test_comp[idx]\n",
    "        \n",
    "        ## Now, trying to \n",
    "        if torch.allclose(torch.tensor(x_comp), x):\n",
    "            img_id = test_comp.depth_files[idx].split(\"/\")[-1]\n",
    "            img_id = str(img_id).split('.')[0][:-1]\n",
    "            ## We cannot use an image!\n",
    "            #quality_dict[str(img_id)] = q_img\n",
    "            iou_quality[str(img_id)] = [int(s), np.max(q_img).astype('float32')]\n",
    "        else:\n",
    "            print(\"Dataloader and Comparison X didn't match\")\n",
    "print(\"Cell Time: \", time.time() - start_cell) ## ~182 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'pcd0100': [1, 1.0517063], 'pcd0101': [1, 1.045923], 'pcd0102': [1, 0.92928237], 'pcd0103': [1, 0.99394953], 'pcd0104': [1, 0.94518286], 'pcd0105': [1, 0.8229798], 'pcd0106': [0, 0.54132044], 'pcd0107': [1, 0.7088535], 'pcd0108': [1, 0.72504544], 'pcd0109': [1, 0.76442176], 'pcd0110': [1, 0.8763616], 'pcd0111': [1, 0.88344646], 'pcd0112': [1, 0.80746746], 'pcd0113': [1, 0.93202347], 'pcd0114': [1, 0.6510281], 'pcd0115': [1, 0.7091662], 'pcd0116': [0, 0.74798334], 'pcd0117': [0, 0.719038], 'pcd0118': [1, 0.74100757], 'pcd0119': [1, 0.862866], 'pcd0120': [1, 0.9704959], 'pcd0121': [1, 0.90548164], 'pcd0122': [1, 0.7081081], 'pcd0123': [1, 0.645414], 'pcd0124': [0, 0.7311125], 'pcd0125': [1, 0.79679567], 'pcd0126': [0, 0.6268924], 'pcd0127': [0, 0.7406696], 'pcd0128': [1, 0.6956099], 'pcd0129': [1, 0.97353715], 'pcd0130': [1, 0.93971324], 'pcd0131': [1, 0.5738125], 'pcd0132': [0, 0.8657288], 'pcd0133': [1, 0.81644785], 'pcd0134': [1, 0.84345424], 'pcd0135': [0, 0.7722464], 'pcd0136': [1, 1.0437478], 'pcd0137': [1, 0.9029961], 'pcd0138': [1, 0.74599534], 'pcd0139': [0, 0.7200018], 'pcd0140': [0, 0.84789485], 'pcd0141': [0, 0.9036605], 'pcd0142': [1, 0.9314141], 'pcd0143': [0, 0.7625416], 'pcd0144': [1, 0.75760025], 'pcd0145': [1, 0.8225378], 'pcd0146': [0, 0.8730053], 'pcd0147': [0, 0.8367903], 'pcd0148': [1, 0.72980934], 'pcd0149': [0, 0.7047314], 'pcd0150': [1, 0.82511216], 'pcd0151': [0, 0.68384814], 'pcd0152': [1, 0.63860536], 'pcd0153': [0, 0.6789703], 'pcd0154': [1, 0.76869136], 'pcd0155': [0, 0.84134513], 'pcd0156': [1, 0.9059219], 'pcd0157': [1, 1.0538085], 'pcd0158': [0, 0.96862346], 'pcd0159': [1, 0.9132614], 'pcd0160': [1, 1.0649694], 'pcd0161': [1, 0.93016106], 'pcd0162': [1, 0.9982871], 'pcd0163': [1, 1.1174839], 'pcd0164': [1, 1.0508962], 'pcd0165': [0, 0.96377695], 'pcd0166': [1, 0.99576306], 'pcd0167': [0, 0.9676283], 'pcd0168': [1, 1.1084523], 'pcd0169': [1, 0.68539554], 'pcd0170': [1, 0.6980573], 'pcd0171': [1, 0.7710225], 'pcd0172': [1, 0.66236377], 'pcd0173': [1, 0.8853729], 'pcd0174': [1, 0.80353594], 'pcd0175': [1, 0.96436006], 'pcd0176': [0, 0.844656], 'pcd0177': [0, 0.96214354], 'pcd0178': [1, 0.9161905], 'pcd0179': [1, 0.90618485], 'pcd0180': [1, 0.84848636], 'pcd0181': [0, 0.885484], 'pcd0182': [1, 1.118811], 'pcd0183': [1, 0.8432096], 'pcd0184': [1, 0.8019581], 'pcd0185': [1, 0.9045399], 'pcd0186': [1, 0.94354266], 'pcd0187': [1, 0.85159487], 'pcd0188': [1, 0.8591515], 'pcd0189': [0, 0.8035351], 'pcd0190': [1, 0.8774871], 'pcd0191': [0, 0.6224302], 'pcd0192': [0, 0.7120563], 'pcd0193': [1, 0.75355625], 'pcd0194': [1, 0.75972754], 'pcd0195': [0, 0.5268128], 'pcd0196': [0, 0.46929824], 'pcd0197': [0, 0.7153507], 'pcd0198': [1, 0.7187804], 'pcd0199': [1, 0.67584616]}\n"
     ]
    }
   ],
   "source": [
    "#print(iou_quality.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pcd0101\npcd0101\n"
     ]
    }
   ],
   "source": [
    "## To get the image id\n",
    "img_id = test_comp.rgb_files[1].split(\"/\")[-1]\n",
    "depth_id = str(img_id).split('.')[0][:-1]\n",
    "print(depth_id)\n",
    "\n",
    "rgb_id = str(img_id).split('.')[0][:-1]\n",
    "print(rgb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'pcd0100': [1, 1.0517063],\n",
       " 'pcd0101': [1, 1.045923],\n",
       " 'pcd0102': [1, 0.92928237],\n",
       " 'pcd0103': [1, 0.99394953],\n",
       " 'pcd0104': [1, 0.94518286],\n",
       " 'pcd0105': [1, 0.8229798],\n",
       " 'pcd0106': [0, 0.54132044],\n",
       " 'pcd0107': [1, 0.7088535],\n",
       " 'pcd0108': [1, 0.72504544],\n",
       " 'pcd0109': [1, 0.76442176],\n",
       " 'pcd0110': [1, 0.8763616],\n",
       " 'pcd0111': [1, 0.88344646],\n",
       " 'pcd0112': [1, 0.80746746],\n",
       " 'pcd0113': [1, 0.93202347],\n",
       " 'pcd0114': [1, 0.6510281],\n",
       " 'pcd0115': [1, 0.7091662],\n",
       " 'pcd0116': [0, 0.74798334],\n",
       " 'pcd0117': [0, 0.719038],\n",
       " 'pcd0118': [1, 0.74100757],\n",
       " 'pcd0119': [1, 0.862866],\n",
       " 'pcd0120': [1, 0.9704959],\n",
       " 'pcd0121': [1, 0.90548164],\n",
       " 'pcd0122': [1, 0.7081081],\n",
       " 'pcd0123': [1, 0.645414],\n",
       " 'pcd0124': [0, 0.7311125],\n",
       " 'pcd0125': [1, 0.79679567],\n",
       " 'pcd0126': [0, 0.6268924],\n",
       " 'pcd0127': [0, 0.7406696],\n",
       " 'pcd0128': [1, 0.6956099],\n",
       " 'pcd0129': [1, 0.97353715],\n",
       " 'pcd0130': [1, 0.93971324],\n",
       " 'pcd0131': [1, 0.5738125],\n",
       " 'pcd0132': [0, 0.8657288],\n",
       " 'pcd0133': [1, 0.81644785],\n",
       " 'pcd0134': [1, 0.84345424],\n",
       " 'pcd0135': [0, 0.7722464],\n",
       " 'pcd0136': [1, 1.0437478],\n",
       " 'pcd0137': [1, 0.9029961],\n",
       " 'pcd0138': [1, 0.74599534],\n",
       " 'pcd0139': [0, 0.7200018],\n",
       " 'pcd0140': [0, 0.84789485],\n",
       " 'pcd0141': [0, 0.9036605],\n",
       " 'pcd0142': [1, 0.9314141],\n",
       " 'pcd0143': [0, 0.7625416],\n",
       " 'pcd0144': [1, 0.75760025],\n",
       " 'pcd0145': [1, 0.8225378],\n",
       " 'pcd0146': [0, 0.8730053],\n",
       " 'pcd0147': [0, 0.8367903],\n",
       " 'pcd0148': [1, 0.72980934],\n",
       " 'pcd0149': [0, 0.7047314],\n",
       " 'pcd0150': [1, 0.82511216],\n",
       " 'pcd0151': [0, 0.68384814],\n",
       " 'pcd0152': [1, 0.63860536],\n",
       " 'pcd0153': [0, 0.6789703],\n",
       " 'pcd0154': [1, 0.76869136],\n",
       " 'pcd0155': [0, 0.84134513],\n",
       " 'pcd0156': [1, 0.9059219],\n",
       " 'pcd0157': [1, 1.0538085],\n",
       " 'pcd0158': [0, 0.96862346],\n",
       " 'pcd0159': [1, 0.9132614],\n",
       " 'pcd0160': [1, 1.0649694],\n",
       " 'pcd0161': [1, 0.93016106],\n",
       " 'pcd0162': [1, 0.9982871],\n",
       " 'pcd0163': [1, 1.1174839],\n",
       " 'pcd0164': [1, 1.0508962],\n",
       " 'pcd0165': [0, 0.96377695],\n",
       " 'pcd0166': [1, 0.99576306],\n",
       " 'pcd0167': [0, 0.9676283],\n",
       " 'pcd0168': [1, 1.1084523],\n",
       " 'pcd0169': [1, 0.68539554],\n",
       " 'pcd0170': [1, 0.6980573],\n",
       " 'pcd0171': [1, 0.7710225],\n",
       " 'pcd0172': [1, 0.66236377],\n",
       " 'pcd0173': [1, 0.8853729],\n",
       " 'pcd0174': [1, 0.80353594],\n",
       " 'pcd0175': [1, 0.96436006],\n",
       " 'pcd0176': [0, 0.844656],\n",
       " 'pcd0177': [0, 0.96214354],\n",
       " 'pcd0178': [1, 0.9161905],\n",
       " 'pcd0179': [1, 0.90618485],\n",
       " 'pcd0180': [1, 0.84848636],\n",
       " 'pcd0181': [0, 0.885484],\n",
       " 'pcd0182': [1, 1.118811],\n",
       " 'pcd0183': [1, 0.8432096],\n",
       " 'pcd0184': [1, 0.8019581],\n",
       " 'pcd0185': [1, 0.9045399],\n",
       " 'pcd0186': [1, 0.94354266],\n",
       " 'pcd0187': [1, 0.85159487],\n",
       " 'pcd0188': [1, 0.8591515],\n",
       " 'pcd0189': [0, 0.8035351],\n",
       " 'pcd0190': [1, 0.8774871],\n",
       " 'pcd0191': [0, 0.6224302],\n",
       " 'pcd0192': [0, 0.7120563],\n",
       " 'pcd0193': [1, 0.75355625],\n",
       " 'pcd0194': [1, 0.75972754],\n",
       " 'pcd0195': [0, 0.5268128],\n",
       " 'pcd0196': [0, 0.46929824],\n",
       " 'pcd0197': [0, 0.7153507],\n",
       " 'pcd0198': [1, 0.7187804],\n",
       " 'pcd0199': [1, 0.67584616]}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# iou_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'fadi_color_pcd0100_pcd1034.txt'"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "first_entry, last_entry = list(iou_quality.keys())[0], list(iou_quality.keys())[-1]\n",
    "fname = \"_\".join((model_name, first_entry, last_entry+\".txt\"))\n",
    "fdir = os.path.join(save_dir, fname)\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the Collected Results!\n",
    "import pickle\n",
    "model_name = \"fadi_color\"\n",
    "save_dir = \"/media/gvk/GVK_Elements/github_repo/Ensemble/Stacking_Test/Stacking_Data/\"\n",
    "first_entry, last_entry = list(iou_quality.keys())[0], list(iou_quality.keys())[-1]\n",
    "fname = \"_\".join((model_name, first_entry, last_entry+\".txt\"))\n",
    "fdir = os.path.join(save_dir, fname)\n",
    "with open(fdir, 'wb') as file_pickle:\n",
    "    pickle.dump(iou_quality, file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "len(iou_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}