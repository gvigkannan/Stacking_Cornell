{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notebook to evaluate and store the results from ggcnn for a sample imageset\n",
    "## Last Trial Run: 7th April 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import sys \n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data \n",
    "import imageio\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggcnn_dir = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/ggcnn_repo/\"\n",
    "fadi_dir = \"/media/gvk/GVK_Elements/github_repo/Ensemble/Experts/Generative/pretrained_weights\"\n",
    "sys.path.append(ggcnn_dir)\n",
    "sys.path.append(fadi_dir)\n",
    "from models.common import post_process_output\n",
    "from utils.dataset_processing import evaluation, grasp \n",
    "from utils.data import get_dataset\n",
    "from utils.dataset_processing.image import DepthImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search Path:  /media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/*/*/pcd*cpos.txt\n"
     ]
    }
   ],
   "source": [
    "## Considering one folder!\n",
    "dataset_path = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/*/\"\n",
    "dataset = get_dataset(\"cornell\")\n",
    "sys.path.insert(0, dataset_path)\n",
    "test_data = dataset(dataset_path, include_depth = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Search Path:  /media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/data01/*/pcd*cpos.txt\n"
     ]
    }
   ],
   "source": [
    "# ## Considering one folder!\n",
    "# folder1_path = \"/media/gvk/GVK_Elements/WPI/Spring2021/DR_Grasping/CurrentFocus/Cornell_Dataset/Full_Cornell/data01/\"\n",
    "# dataset = get_dataset(\"cornell\")\n",
    "# sys.path.insert(0, folder1_path)\n",
    "# test_data = dataset(folder1_path, include_depth = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(test_data.depth_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/media/gvk/GVK_Elements/py_linux/ensemble_dr_linux/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/media/gvk/GVK_Elements/py_linux/ensemble_dr_linux/lib/python3.8/site-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.ConvTranspose2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "## Model Loading:\n",
    "fadi_depth_dir = \"/media/gvk/GVK_Elements/github_repo/Stacking_Cornell/Experts/Generative/pretrained_weights/depth/ggcnn_epoch_23_cornell\"\n",
    "depth_net = torch.load(fadi_depth_dir)\n",
    "net = depth_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comp = test_data\n",
    "test_data = torch.utils.data.DataLoader(test_data, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cell Time:  0.21756196022033691\n"
     ]
    }
   ],
   "source": [
    "# ##  Trial for each test image\n",
    "# start_cell = time.time()\n",
    "# results = {'correct': 0, 'failed': 0}\n",
    "# iou_quality = {}\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     ## For each test image\n",
    "#     ## Just testing for one single image\n",
    "#     x, y, didx, rot, zoom =  next(iter(test_data))\n",
    "#     idx = 0\n",
    "#     xc = x.to(device)\n",
    "#     yc = [yi.to(device) for yi in y]\n",
    "#     lossd = net.compute_loss(xc, yc)    ## Ensure that your outputs are from a dataloader!\n",
    "\n",
    "#     q_img, ang_img, width_img = post_process_output( lossd['pred']['pos'], lossd['pred']['cos'], lossd['pred']['sin'], lossd['pred']['width'])\n",
    "#     s = evaluation.calculate_iou_match(q_img, ang_img, test_data.dataset.get_gtbb(didx, rot, zoom), no_grasps = 1, grasp_width = width_img)\n",
    "\n",
    "#     if s:\n",
    "#         results['correct'] += 1\n",
    "#     else:\n",
    "#         results['failed'] += 1\n",
    "\n",
    "#     iou_dict = {}\n",
    "#     ## Now to compare and create a dictionary that stores the quality given image name\n",
    "#     x_comp, _, _, _, _ = test_comp[idx]\n",
    "#     #print(torch.allclose(torch.tensor(x_comp), x))\n",
    "#     if torch.allclose(torch.tensor(x_comp), x):\n",
    "#         img_id = test_comp.depth_files[0].split(\"/\")[-1]\n",
    "\n",
    "#         ## We cannot use an image!\n",
    "#         #quality_dict[str(img_id)] = q_img\n",
    "#         image_id = str(img_id).split('.')[0][:-1]\n",
    "#         iou_quality[image_id] = [int(s), np.max(q_img).astype('float32')]\n",
    "#     else:\n",
    "#         print(\"Dataloader and Comparison X didn't match\")\n",
    "\n",
    "# print(\"Cell Time: \", time.time() - start_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cell Time:  103.87643551826477\n"
     ]
    }
   ],
   "source": [
    "results = {'correct': 0, 'failed': 0}\n",
    "start_cell = time.time()\n",
    "iou_quality = {}\n",
    "with torch.no_grad():\n",
    "\n",
    "    ## For each test image\n",
    "    ## Just testing for one single image\n",
    "    #x, y, didx, rot, zoom =  next(iter(test_data))\n",
    "    for idx, (x, y, didx, rot, zoom) in enumerate(test_data):\n",
    "        xc = x.to(device)\n",
    "        yc = [yi.to(device) for yi in y]\n",
    "        lossd = net.compute_loss(xc, yc)\n",
    "\n",
    "        q_img, ang_img, width_img = post_process_output( lossd['pred']['pos'], lossd['pred']['cos'], lossd['pred']['sin'], lossd['pred']['width'])\n",
    "        s = evaluation.calculate_iou_match(q_img, ang_img, test_data.dataset.get_gtbb(didx, rot, zoom), no_grasps = 1, grasp_width = width_img)\n",
    "\n",
    "        if s:\n",
    "            results['correct'] += 1\n",
    "        else:\n",
    "            results['failed'] += 1\n",
    "\n",
    "        ## Need to store: q_img and img_id\n",
    "        ## Now to compare and create a dictionary that stores the quality given image name\n",
    "        x_comp, _, _, _, _ = test_comp[idx]\n",
    "        \n",
    "        ## Now, trying to \n",
    "        if torch.allclose(torch.tensor(x_comp), x):\n",
    "            img_id = test_comp.depth_files[idx].split(\"/\")[-1]\n",
    "            img_id = str(img_id).split('.')[0][:-1]\n",
    "            ## We cannot use an image!\n",
    "            #quality_dict[str(img_id)] = q_img\n",
    "            iou_quality[str(img_id)] = [int(s), np.max(q_img).astype('float32')]\n",
    "        else:\n",
    "            print(\"Dataloader and Comparison X didn't match\")\n",
    "print(\"Cell Time: \", time.time() - start_cell) ## ~104s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "885\n"
     ]
    }
   ],
   "source": [
    "print(len(iou_quality.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pcd0101\npcd0101\n"
     ]
    }
   ],
   "source": [
    "## To get the image id\n",
    "img_id = test_comp.rgb_files[1].split(\"/\")[-1]\n",
    "depth_id = str(img_id).split('.')[0][:-1]\n",
    "print(depth_id)\n",
    "\n",
    "rgb_id = str(img_id).split('.')[0][:-1]\n",
    "print(rgb_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the Collected Results!\n",
    "import pickle\n",
    "model_name = \"fadi_depth\"\n",
    "save_dir = \"/media/gvk/GVK_Elements/github_repo/Ensemble/Stacking_Test/Stacking_Data/\"\n",
    "first_entry, last_entry = list(iou_quality.keys())[0], list(iou_quality.keys())[-1]\n",
    "fname = \"_\".join((model_name, first_entry, last_entry+\".txt\"))\n",
    "fdir = os.path.join(save_dir, fname)\n",
    "with open(fdir, 'wb') as file_pickle:\n",
    "    pickle.dump(iou_quality, file_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/media/gvk/GVK_Elements/github_repo/Ensemble/Stacking_Test/Stacking_Data/fadi_depth_pcd0100_pcd1034.txt'"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "fdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}